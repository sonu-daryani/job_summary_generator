# AI Model Configuration
# Set to true to use local models, false to use Hugging Face API
USE_LOCAL_MODEL=true

# Llama 4 Scout Configuration (when USE_LOCAL_MODEL=true)
# Set to true to use Llama 4 Scout, false to use Llama 2
USE_LLAMA4=true
# Model ID for Llama 4 Scout
LLAMA4_MODEL_ID=llama-4-scout
# Custom URL for Llama 4 Scout access (provided by Meta)
LLAMA4_CUSTOM_URL=https://*************

# Llama 2 Model Configuration (fallback when USE_LLAMA4=false)
# Available models: meta-llama/Llama-2-7b-chat-hf, meta-llama/Llama-2-13b-chat-hf, meta-llama/Llama-2-70b-chat-hf
LLAMA_MODEL_NAME=meta-llama/Llama-2-7b-chat-hf
# Device: auto (auto-detect), cpu, cuda, mps (Apple Silicon)
DEVICE=auto
# Optional: Set max GPU memory (e.g., "8GB", "16GB")
# MAX_MEMORY=8GB

# Hugging Face API Configuration (fallback when USE_LOCAL_MODEL=false)
# Get your free API key from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_free_huggingface_api_key_here
HUGGINGFACE_API_URL=https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium

# Model Selection (0=gpt2, 1=distilgpt2, 2=DialoGPT-small, 3=DialoGPT-medium)
MODEL_INDEX=0

# Application Configuration
APP_NAME=Job Summary Generator
DEBUG=True
HOST=0.0.0.0
PORT=8000
